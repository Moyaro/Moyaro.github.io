<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link rel="stylesheet" href="/assets/css/style.css?v=e2b063d11b5c15499d76b5399555b066ded25069">
    <title>whoimi by liangz0707</title>
  </head>

  <body>

    <header>
      <div class="container">
        <h1>whoimi</h1>
        <h2>A geek blog</h2>
        <section id="downloads">
          
          <a href="http://github.com/liangz0707/whoimi" class="btn btn-github"><span class="icon"></span>View on GitHub</a>
        </section>
      </div>
    </header>

    <div class="container">
      <section id="main_content">
        <h2 id="hadoop安装ubuntu1404">Hadoop安装（Ubuntu14.04）</h2>

<ol>
  <li>安装java</li>
  <li>配置JAVA_HOME</li>
  <li>下载hadoop2.7解压即可使用</li>
</ol>

<h2 id="hdfs">HDFS</h2>

<p>在下面的配置文件中配置HDFS:</p>

<p>etc/hadoop/core-site.xml:</p>

<div class="language-xml highlighter-rouge"><pre class="highlight"><code><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>hdfs://localhost:9000<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre>
</div>

<p>etc/hadoop/hdfs-site.xml:</p>

<div class="language-xml highlighter-rouge"><pre class="highlight"><code><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre>
</div>

<p>完成以上两个配置文件尝试进行ssh链接</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>ssh localhost
</code></pre>
</div>

<p>使用下面的命令进行无密码ssh链接:</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>ssh-keygen -t dsa -P <span class="s1">''</span> -f ~/.ssh/id_dsa
<span class="gp">$ </span>cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
<span class="gp">$ </span>chmod 0600 ~/.ssh/authorized_keys
</code></pre>
</div>

<ol>
  <li>Format the filesystem:</li>
</ol>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="nv">$bin</span>/hdfs namenode -format
</code></pre>
</div>

<ol>
  <li>Start NameNode daemon and DataNode daemon:</li>
</ol>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sbin/start-dfs.sh
</code></pre>
</div>

<ol>
  <li>
    <p>在浏览器中查看NameNode
NameNode - http://localhost:50070/</p>
  </li>
  <li>
    <p>创建目录</p>
  </li>
</ol>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>bin/hdfs dfs -mkdir /user
<span class="gp">$ </span>bin/hdfs dfs -mkdir /user/&lt;username&gt;
</code></pre>
</div>

<ol>
  <li>将文件拷贝到HDFS文件系统:</li>
</ol>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>bin/hdfs dfs -put etc/hadoop input
</code></pre>
</div>

<ol>
  <li>Run some of the examples provided:</li>
</ol>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output <span class="s1">'dfs[a-z.]+'</span>
</code></pre>
</div>

<ol>
  <li>Examine the output files: Copy the output files from the distributed filesystem to the local filesystem and examine them:</li>
</ol>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>bin/hdfs dfs -get output output
<span class="gp">$ </span>cat output/<span class="k">*</span>
</code></pre>
</div>

<ol>
  <li>When you’re done, stop the daemons with:</li>
</ol>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sbin/stop-dfs.sh
</code></pre>
</div>

<h2 id="mapreduce">MapReduce</h2>

<p>编写map reduce文件</p>

<div class="language-java highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">java.io.IOException</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.StringTokenizer</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.fs.Path</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.io.IntWritable</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.io.Text</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapreduce.Job</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapreduce.Mapper</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapreduce.Reducer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapreduce.lib.input.FileInputFormat</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapreduce.lib.output.FileOutputFormat</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">WordCount</span> <span class="o">{</span>

  <span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">TokenizerMapper</span> <span class="kd">extends</span> <span class="n">Mapper</span><span class="o">&lt;</span><span class="n">Object</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">&gt;{</span>

    <span class="kd">private</span> <span class="kd">final</span> <span class="kd">static</span> <span class="n">IntWritable</span> <span class="n">one</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IntWritable</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>
    <span class="kd">private</span> <span class="n">Text</span> <span class="n">word</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Text</span><span class="o">();</span>

    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">map</span><span class="o">(</span><span class="n">Object</span> <span class="n">key</span><span class="o">,</span> <span class="n">Text</span> <span class="n">value</span><span class="o">,</span> <span class="n">Context</span> <span class="n">context</span> <span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span><span class="o">,</span> <span class="n">InterruptedException</span> <span class="o">{</span>
      <span class="n">StringTokenizer</span> <span class="n">itr</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StringTokenizer</span><span class="o">(</span><span class="n">value</span><span class="o">.</span><span class="na">toString</span><span class="o">());</span>
      <span class="k">while</span> <span class="o">(</span><span class="n">itr</span><span class="o">.</span><span class="na">hasMoreTokens</span><span class="o">())</span> <span class="o">{</span>
        <span class="n">word</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">itr</span><span class="o">.</span><span class="na">nextToken</span><span class="o">());</span>
        <span class="n">context</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">word</span><span class="o">,</span> <span class="n">one</span><span class="o">);</span>
      <span class="o">}</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">IntSumReducer</span> <span class="kd">extends</span> <span class="n">Reducer</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span><span class="n">IntWritable</span><span class="o">,</span><span class="n">Text</span><span class="o">,</span><span class="n">IntWritable</span><span class="o">&gt;</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="n">IntWritable</span> <span class="n">result</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IntWritable</span><span class="o">();</span>

    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">reduce</span><span class="o">(</span><span class="n">Text</span> <span class="n">key</span><span class="o">,</span> <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">IntWritable</span><span class="o">&gt;</span> <span class="n">values</span><span class="o">,</span><span class="n">Context</span> <span class="n">context</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span><span class="o">,</span> <span class="n">InterruptedException</span> <span class="o">{</span>
      <span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
      <span class="k">for</span> <span class="o">(</span><span class="n">IntWritable</span> <span class="n">val</span> <span class="o">:</span> <span class="n">values</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">sum</span> <span class="o">+=</span> <span class="n">val</span><span class="o">.</span><span class="na">get</span><span class="o">();</span>
      <span class="o">}</span>
      <span class="n">result</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">sum</span><span class="o">);</span>
      <span class="n">context</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">result</span><span class="o">);</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="n">Configuration</span> <span class="n">conf</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Configuration</span><span class="o">();</span>
    <span class="n">Job</span> <span class="n">job</span> <span class="o">=</span> <span class="n">Job</span><span class="o">.</span><span class="na">getInstance</span><span class="o">(</span><span class="n">conf</span><span class="o">,</span> <span class="s">"word count"</span><span class="o">);</span>
    <span class="n">job</span><span class="o">.</span><span class="na">setJarByClass</span><span class="o">(</span><span class="n">WordCount</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
    <span class="n">job</span><span class="o">.</span><span class="na">setMapperClass</span><span class="o">(</span><span class="n">TokenizerMapper</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
    <span class="n">job</span><span class="o">.</span><span class="na">setCombinerClass</span><span class="o">(</span><span class="n">IntSumReducer</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
    <span class="n">job</span><span class="o">.</span><span class="na">setReducerClass</span><span class="o">(</span><span class="n">IntSumReducer</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
    <span class="n">job</span><span class="o">.</span><span class="na">setOutputKeyClass</span><span class="o">(</span><span class="n">Text</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
    <span class="n">job</span><span class="o">.</span><span class="na">setOutputValueClass</span><span class="o">(</span><span class="n">IntWritable</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
    <span class="n">FileInputFormat</span><span class="o">.</span><span class="na">addInputPath</span><span class="o">(</span><span class="n">job</span><span class="o">,</span> <span class="k">new</span> <span class="n">Path</span><span class="o">(</span><span class="n">args</span><span class="o">[</span><span class="mi">0</span><span class="o">]));</span>
    <span class="n">FileOutputFormat</span><span class="o">.</span><span class="na">setOutputPath</span><span class="o">(</span><span class="n">job</span><span class="o">,</span> <span class="k">new</span> <span class="n">Path</span><span class="o">(</span><span class="n">args</span><span class="o">[</span><span class="mi">1</span><span class="o">]));</span>
    <span class="n">System</span><span class="o">.</span><span class="na">exit</span><span class="o">(</span><span class="n">job</span><span class="o">.</span><span class="na">waitForCompletion</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> <span class="o">?</span> <span class="mi">0</span> <span class="o">:</span> <span class="mi">1</span><span class="o">);</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre>
</div>

<p>制作成jar包</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>bin/hadoop com.sun.tools.javac.Main WordCount.java
<span class="gp">$ </span>jar cf wc.jar WordCount<span class="k">*</span>.class
</code></pre>
</div>

<p>启动hdfs并将文件提交到hdfs中:参考HDFS</p>

<p>执行程序：</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code>bin/hadoop jar wc.jar WordCount /user/liangz14/input /user/liangz14/output
</code></pre>
</div>

<p>查看结果</p>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code>bin/hadoop fs -cat /user/joe/wordcount/output/part-r-00000<span class="sb">`</span>
</code></pre>
</div>
<p>-libjars, -files and -archives: 参数的使用  分别用来制定jar包，指定文件，和未解压文件 通过#也可以致命具体解压后的文件名
，不同参数之间用‘’，‘分割</p>

<h3 id="mr的一般过程">mr的一般过程</h3>

<div class="language-xml highlighter-rouge"><pre class="highlight"><code>(input) <span class="nt">&lt;k1</span><span class="err">,</span> <span class="err">v1</span><span class="nt">&gt;</span> -&gt; map -&gt; <span class="nt">&lt;k2</span><span class="err">,</span> <span class="err">v2</span><span class="nt">&gt;</span> -&gt; combine -&gt; <span class="nt">&lt;k2</span><span class="err">,</span> <span class="err">v2</span><span class="nt">&gt;</span> -&gt; reduce -&gt; <span class="nt">&lt;k3</span><span class="err">,</span> <span class="err">v3</span><span class="nt">&gt;</span> (output)
combine和reducer的作用一样 设置的方法：  job.setCombinerClass(IntSumReducer.class);
</code></pre>
</div>

<h3 id="main方法中的设置">MAIN方法中的设置</h3>
<h4 id="mapper-">Mapper ：</h4>
<p>通过Job.setMapperClass(Class) 设置map</p>

<p>map的结果通过context.write(WritableComparable, Writable).进行收集</p>

<p>之后会根据比较器进行分组： Job.setGroupingComparatorClass(Class).</p>

<p>之后map的结果救回被排序 并被划分给不同的reducer，划分任务的个数和reduce任务的个数一样</p>

<p>可以制定那个key进入那个Reducer：通过实现客户自定义的划分器</p>

<p>用户可以选择是有使用一个结合器 Job.setCombinerClass(Class)，来实现中间结果的本地聚合，可以减少数据传输的总量（从Mapper到Reducer）</p>

<p>中间结果总是会进行排序，根据：key的长度，key，值的长度，值。可以控制是否压缩，如何压缩。</p>

<h4 id="maps的数量">Maps的数量：</h4>
<p>有输入数据的总数决定。输入文件的总的块数</p>

<p>maps的数量最好为每个节点10到100  经过设置到了每个cpu最多300</p>

<p>Configuration.set(MRJobConfig.NUM_MAPS, int) 可以进行设置</p>

<h4 id="mapper细节">Mapper细节：</h4>

<p>Map首先调用setup（context）操作</p>

<p>然后调用map（object，object，context）操作</p>

<p>最后调用cleanup（context）操作</p>

<p>map可以通过RawComparator 控制分组和排序</p>

<p>通过Partitioner控制那个key进入那个Reducer</p>

<p>通过setCombinerClass 可以进行本地的组合</p>

<p>通过 CompressionCodec控制压缩</p>

<h4 id="reducer">Reducer：</h4>
<p>Reducer将中间结果（有共同的key）装换成一个更小的值的集合</p>

<p>Job.setNumReduceTasks(int).来设置reduce的数量</p>

<p>Job.setReducerClass(Class) 来对reduce进行设置</p>

<p>每一个 &lt;key, (list of values)&gt;都会调用一次</p>

<p>Reducer有三个主要的阶段shuffle, sort and reduce.</p>

<h4 id="shuffle">Shuffle：</h4>
<p>框架从所有Mapper的排序结果中获取相关的划分</p>

<p>Sort：框架通过key将Reducer的输入进行分组，因为不同的mapper可能有相同key的输出</p>

<p>Job.setSortComparatorClass(Class).可以生命子集的规则，指定如何分组</p>

<p>Reduce：每一个key都会执行一个reduce，这个结果会通过Context.write写入到文件系统中。</p>

<p>Reduce的输出结果是没有经过排序的</p>

<p>Recude的个数 0.95 *  节点数 * 节点最大容器数 - 1.75 * …</p>

<h4 id="partitioner">Partitioner</h4>
<p>用来将key空间进行划分，最终划分的总数和reduce任务的总数是一样的
HashPartitioner是默认的划分器</p>

<h4 id="counter">Counter</h4>
<p>计数器时统计工具，M R都能用来统计</p>

<p>Hadoop MapReduce comes bundled with a library of generally useful mappers, reducers, and partitioners.</p>

<p>Hadoop的MR 是由一系列的 M  R 和P操作库 组成的</p>

<h4 id="job设置">JOB设置</h4>
<p>Mapper, combiner (if any), Partitioner, Reducer, InputFormat, OutputFormat implementations</p>

<p>其中FileInputFormat设置输入文件的集合路径</p>

<p>FileOutputFormat设置输出路径</p>

<h2 id="hdfs常用命令">HDFS常用命令</h2>

<div class="language-shell highlighter-rouge"><pre class="highlight"><code>hadoop fs -ls /
hadoop fs -lsr
hadoop fs -mkdir /user/hadoop
hadoop fs -put a.txt /user/hadoop/
hadoop fs -get /user/hadoop/a.txt /
hadoop fs -cp src dst
hadoop fs -mv src dst
hadoop fs -cat /user/hadoop/a.txt
hadoop fs -rm /user/hadoop/a.txt
hadoop fs -rmr /user/hadoop/a.txt
hadoop fs -text /user/hadoop/a.txt
hadoop fs -copyFromLocal localsrc dst 与hadoop fs -put功能类似。
hadoop fs -moveFromLocal localsrc dst 将本地文件上传到hdfs，同时删除本地文件。

hadoop dfsadmin -report
hadoop dfsadmin -safemode enter | leave | get | <span class="nb">wait
</span>hadoop dfsadmin -setBalancerBandwidth 1000
</code></pre>
</div>

<p><a href="/">back</a></p>


      </section>
    </div>

    


    <footer>
      text footer
    </footer>
  </body>
</html>